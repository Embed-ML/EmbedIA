{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt0VLZYvwmfD"
      },
      "source": [
        "<div align=\"left\">\n",
        "  <h1>EmbedIA</h1>\n",
        "  <p>EmbedIA is a machine learning framework for developing applications on microcontrollers.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9zpfPkcxbtd"
      },
      "source": [
        "## Import framework from Github (run only in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install larq"
      ],
      "metadata": {
        "id": "VHVRNEBYewqv",
        "outputId": "172382d6-9db6-429f-bb6c-8cdf87c2ec64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting larq\n",
            "  Downloading larq-0.13.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=19.2 in /usr/local/lib/python3.9/dist-packages (from larq) (23.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from larq) (1.22.4)\n",
            "Collecting terminaltables>=3.1.0\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: terminaltables, larq\n",
            "Successfully installed larq-0.13.0 terminaltables-3.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LT3-lW8o_vt",
        "outputId": "2afe2e6d-a57a-4b7b-8cec-6b99d71d7bba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EmbedIA'...\n",
            "remote: Enumerating objects: 811, done.\u001b[K\n",
            "remote: Counting objects: 100% (811/811), done.\u001b[K\n",
            "remote: Compressing objects: 100% (419/419), done.\u001b[K\n",
            "remote: Total 811 (delta 428), reused 719 (delta 347), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (811/811), 12.17 MiB | 4.54 MiB/s, done.\n",
            "Resolving deltas: 100% (428/428), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Embed-ML/EmbedIA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9uOnWBJtr0p",
        "outputId": "21ca6433-a61b-49e5-cc8f-f0f75e3b4762"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EmbedIA\n"
          ]
        }
      ],
      "source": [
        "%cd EmbedIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuRohaVQYgyR"
      },
      "source": [
        "## Load dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOZh360UZMYR",
        "outputId": "8305a946-b8b0-46b8-bad7-402e44144f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape (1437, 8, 8, 1)\n",
            "x_test.shape (360, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0 to not apply normalization\n",
        "# 1 for normalization [-0.5, 0.5], \n",
        "# 2 for normalization z score, \n",
        "_normalize = 2 \n",
        "\n",
        "def normalization0dot5(x):\n",
        "    '''\n",
        "        Normalization of values in the range [-0.5; 0.5]\n",
        "        Params:\n",
        "            x: numpy array to be normalized\n",
        "        Return:\n",
        "            x: normalized numpy array\n",
        "    '''\n",
        "    x = x/np.max(x)\n",
        "    x = x-0.5\n",
        "    return x\n",
        "\n",
        "def z_score(X_train, x_test):\n",
        "    '''\n",
        "        Normalization z score, uses mean and standard deviation of train vector\n",
        "        Params:\n",
        "            X_train: array of train numpy to be normalized\n",
        "            x_test: array of test numpy to be normalized\n",
        "        Return:\n",
        "            x_train, x_test: normalized numpy vectors\n",
        "    '''\n",
        "    x_mean= np.mean(X_train)\n",
        "    x_std= np.std(X_train)\n",
        "    \n",
        "    x_train= (X_train-x_mean)/x_std\n",
        "    x_test= (x_test-x_mean)/x_std\n",
        "    return x_train, x_test\n",
        "\n",
        "def load_dataset(_normalize):\n",
        "    '''\n",
        "        Load the sklearn digits dataset, applying the indicated normalization.\n",
        "        Params:\n",
        "            _normalize: normalization to be applied\n",
        "        Return:\n",
        "           X_train, X_test: training set\n",
        "           y_train, y_test: test set\n",
        "    '''\n",
        "\n",
        "    digits = load_digits()\n",
        "    \n",
        "    if _normalize == 1:\n",
        "        digits.images = normalization0dot5(digits.images)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(digits.images , digits.target, test_size=0.2, shuffle=True)\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "    if _normalize == 2:\n",
        "        X_train, X_test = z_score(X_train, X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "x_train, x_test, y_train, y_test = load_dataset(_normalize)\n",
        "\n",
        "print('x_train.shape', x_train.shape)\n",
        "print('x_test.shape', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmUZiTEGcADx"
      },
      "source": [
        "## Creating and training a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b7ZtwtOcXqq",
        "outputId": "1f49578a-917d-4c09-edfd-a8c5715f88a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"EmbedIA_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 3, 3, 8)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 2, 2, 16)          528       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,818\n",
            "Trainable params: 1,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D, BatchNormalization\n",
        "\n",
        "def create_model(x_train, y_train, y_test):\n",
        "    '''\n",
        "        Create a model\n",
        "        Input parameters:\n",
        "            x_train: training data\n",
        "            y_train, y_test: labels of the data involved (including test data)\n",
        "\n",
        "        return\n",
        "            model: sequential layers model\n",
        "    '''\n",
        "    classes = max(y_test.max(),y_train.max())+1\n",
        "\n",
        "    model = Sequential(name=\"EmbedIA_model\")\n",
        "\n",
        "    model.add(Conv2D(8, kernel_size=(3, 3), input_shape=x_train[0].shape,activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(16, kernel_size=(2, 2),activation='relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(16,activation='relu'))\n",
        "    model.add(Dense(classes,activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', \n",
        "                    loss='sparse_categorical_crossentropy', \n",
        "                    metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "model = create_model(x_train, y_train, y_test)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNA75Qmc0zx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyyEsZKpco9z",
        "outputId": "ebb0bf30-9a00-455f-80ba-955190f45fa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "45/45 [==============================] - 2s 11ms/step - loss: 2.1837 - acc: 0.2289 - val_loss: 2.0325 - val_acc: 0.3333\n",
            "Epoch 2/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 1.7769 - acc: 0.4836 - val_loss: 1.5738 - val_acc: 0.5556\n",
            "Epoch 3/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 1.2163 - acc: 0.7196 - val_loss: 0.9774 - val_acc: 0.7694\n",
            "Epoch 4/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.7703 - acc: 0.8232 - val_loss: 0.6578 - val_acc: 0.8278\n",
            "Epoch 5/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.5303 - acc: 0.8803 - val_loss: 0.5143 - val_acc: 0.8528\n",
            "Epoch 6/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.4063 - acc: 0.9012 - val_loss: 0.3760 - val_acc: 0.9000\n",
            "Epoch 7/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.3222 - acc: 0.9255 - val_loss: 0.3145 - val_acc: 0.9194\n",
            "Epoch 8/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2718 - acc: 0.9346 - val_loss: 0.2615 - val_acc: 0.9222\n",
            "Epoch 9/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.2335 - acc: 0.9422 - val_loss: 0.2329 - val_acc: 0.9389\n",
            "Epoch 10/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.2027 - acc: 0.9513 - val_loss: 0.2213 - val_acc: 0.9389\n",
            "Epoch 11/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1826 - acc: 0.9485 - val_loss: 0.1918 - val_acc: 0.9500\n",
            "Epoch 12/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1648 - acc: 0.9589 - val_loss: 0.1734 - val_acc: 0.9528\n",
            "Epoch 13/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1445 - acc: 0.9610 - val_loss: 0.1567 - val_acc: 0.9611\n",
            "Epoch 14/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1366 - acc: 0.9610 - val_loss: 0.1466 - val_acc: 0.9639\n",
            "Epoch 15/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.1256 - acc: 0.9652 - val_loss: 0.1476 - val_acc: 0.9667\n",
            "Epoch 16/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1185 - acc: 0.9687 - val_loss: 0.1288 - val_acc: 0.9639\n",
            "Epoch 17/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.1105 - acc: 0.9708 - val_loss: 0.1298 - val_acc: 0.9667\n",
            "Epoch 18/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.1032 - acc: 0.9722 - val_loss: 0.1204 - val_acc: 0.9667\n",
            "Epoch 19/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0944 - acc: 0.9777 - val_loss: 0.1258 - val_acc: 0.9667\n",
            "Epoch 20/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0964 - acc: 0.9729 - val_loss: 0.1149 - val_acc: 0.9694\n",
            "Epoch 21/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0862 - acc: 0.9777 - val_loss: 0.1109 - val_acc: 0.9722\n",
            "Epoch 22/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0845 - acc: 0.9770 - val_loss: 0.1057 - val_acc: 0.9694\n",
            "Epoch 23/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0774 - acc: 0.9805 - val_loss: 0.1072 - val_acc: 0.9722\n",
            "Epoch 24/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0731 - acc: 0.9826 - val_loss: 0.1042 - val_acc: 0.9722\n",
            "Epoch 25/120\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 0.0663 - acc: 0.9847 - val_loss: 0.0925 - val_acc: 0.9778\n",
            "Epoch 26/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0656 - acc: 0.9833 - val_loss: 0.1015 - val_acc: 0.9722\n",
            "Epoch 27/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0659 - acc: 0.9840 - val_loss: 0.0868 - val_acc: 0.9806\n",
            "Epoch 28/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0621 - acc: 0.9882 - val_loss: 0.0868 - val_acc: 0.9694\n",
            "Epoch 29/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0570 - acc: 0.9861 - val_loss: 0.0943 - val_acc: 0.9722\n",
            "Epoch 30/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0592 - acc: 0.9861 - val_loss: 0.0969 - val_acc: 0.9694\n",
            "Epoch 31/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0576 - acc: 0.9833 - val_loss: 0.0832 - val_acc: 0.9750\n",
            "Epoch 32/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0541 - acc: 0.9854 - val_loss: 0.0840 - val_acc: 0.9806\n",
            "Epoch 33/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0470 - acc: 0.9903 - val_loss: 0.0794 - val_acc: 0.9806\n",
            "Epoch 34/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0436 - acc: 0.9896 - val_loss: 0.0822 - val_acc: 0.9806\n",
            "Epoch 35/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0433 - acc: 0.9910 - val_loss: 0.0864 - val_acc: 0.9806\n",
            "Epoch 36/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0399 - acc: 0.9903 - val_loss: 0.0798 - val_acc: 0.9833\n",
            "Epoch 37/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0362 - acc: 0.9916 - val_loss: 0.0782 - val_acc: 0.9806\n",
            "Epoch 38/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0360 - acc: 0.9937 - val_loss: 0.0832 - val_acc: 0.9833\n",
            "Epoch 39/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0339 - acc: 0.9944 - val_loss: 0.0778 - val_acc: 0.9806\n",
            "Epoch 40/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0332 - acc: 0.9944 - val_loss: 0.0767 - val_acc: 0.9778\n",
            "Epoch 41/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0311 - acc: 0.9951 - val_loss: 0.0743 - val_acc: 0.9778\n",
            "Epoch 42/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0294 - acc: 0.9965 - val_loss: 0.0734 - val_acc: 0.9833\n",
            "Epoch 43/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0289 - acc: 0.9937 - val_loss: 0.0742 - val_acc: 0.9806\n",
            "Epoch 44/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0294 - acc: 0.9937 - val_loss: 0.0708 - val_acc: 0.9778\n",
            "Epoch 45/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0270 - acc: 0.9958 - val_loss: 0.0836 - val_acc: 0.9778\n",
            "Epoch 46/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0239 - acc: 0.9965 - val_loss: 0.0739 - val_acc: 0.9778\n",
            "Epoch 47/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0229 - acc: 0.9979 - val_loss: 0.0913 - val_acc: 0.9778\n",
            "Epoch 48/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0240 - acc: 0.9951 - val_loss: 0.0918 - val_acc: 0.9667\n",
            "Epoch 49/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0216 - acc: 0.9972 - val_loss: 0.0815 - val_acc: 0.9806\n",
            "Epoch 50/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0212 - acc: 0.9979 - val_loss: 0.0778 - val_acc: 0.9778\n",
            "Epoch 51/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0219 - acc: 0.9951 - val_loss: 0.0779 - val_acc: 0.9806\n",
            "Epoch 52/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0192 - acc: 0.9972 - val_loss: 0.0706 - val_acc: 0.9778\n",
            "Epoch 53/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0188 - acc: 0.9979 - val_loss: 0.0827 - val_acc: 0.9750\n",
            "Epoch 54/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0188 - acc: 0.9965 - val_loss: 0.0829 - val_acc: 0.9778\n",
            "Epoch 55/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0162 - acc: 0.9979 - val_loss: 0.0781 - val_acc: 0.9806\n",
            "Epoch 56/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0156 - acc: 0.9972 - val_loss: 0.0843 - val_acc: 0.9750\n",
            "Epoch 57/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0148 - acc: 0.9986 - val_loss: 0.0768 - val_acc: 0.9778\n",
            "Epoch 58/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0150 - acc: 0.9979 - val_loss: 0.0773 - val_acc: 0.9806\n",
            "Epoch 59/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0139 - acc: 0.9972 - val_loss: 0.0781 - val_acc: 0.9778\n",
            "Epoch 60/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0127 - acc: 0.9979 - val_loss: 0.0800 - val_acc: 0.9806\n",
            "Epoch 61/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0132 - acc: 0.9986 - val_loss: 0.0756 - val_acc: 0.9750\n",
            "Epoch 62/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0113 - acc: 0.9986 - val_loss: 0.0762 - val_acc: 0.9778\n",
            "Epoch 63/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0118 - acc: 0.9979 - val_loss: 0.0918 - val_acc: 0.9750\n",
            "Epoch 64/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0110 - acc: 0.9986 - val_loss: 0.0775 - val_acc: 0.9778\n",
            "Epoch 65/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0096 - acc: 0.9993 - val_loss: 0.0817 - val_acc: 0.9750\n",
            "Epoch 66/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0784 - val_acc: 0.9778\n",
            "Epoch 67/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0090 - acc: 0.9993 - val_loss: 0.0809 - val_acc: 0.9750\n",
            "Epoch 68/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0099 - acc: 0.9986 - val_loss: 0.0817 - val_acc: 0.9750\n",
            "Epoch 69/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0091 - acc: 0.9993 - val_loss: 0.0696 - val_acc: 0.9806\n",
            "Epoch 70/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0084 - acc: 0.9993 - val_loss: 0.0799 - val_acc: 0.9806\n",
            "Epoch 71/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0076 - acc: 0.9993 - val_loss: 0.0960 - val_acc: 0.9806\n",
            "Epoch 72/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0752 - val_acc: 0.9778\n",
            "Epoch 73/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9722\n",
            "Epoch 74/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0072 - acc: 0.9993 - val_loss: 0.0837 - val_acc: 0.9750\n",
            "Epoch 75/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9778\n",
            "Epoch 76/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.0825 - val_acc: 0.9750\n",
            "Epoch 77/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0766 - val_acc: 0.9778\n",
            "Epoch 78/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0816 - val_acc: 0.9750\n",
            "Epoch 79/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0781 - val_acc: 0.9750\n",
            "Epoch 80/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0744 - val_acc: 0.9778\n",
            "Epoch 81/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0885 - val_acc: 0.9750\n",
            "Epoch 82/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9750\n",
            "Epoch 83/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.1043 - val_acc: 0.9750\n",
            "Epoch 84/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9750\n",
            "Epoch 85/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0915 - val_acc: 0.9750\n",
            "Epoch 86/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 0.0774 - val_acc: 0.9750\n",
            "Epoch 87/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0981 - val_acc: 0.9750\n",
            "Epoch 88/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9750\n",
            "Epoch 89/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0796 - val_acc: 0.9778\n",
            "Epoch 90/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0884 - val_acc: 0.9722\n",
            "Epoch 91/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0910 - val_acc: 0.9722\n",
            "Epoch 92/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0846 - val_acc: 0.9750\n",
            "Epoch 93/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9722\n",
            "Epoch 94/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0823 - val_acc: 0.9750\n",
            "Epoch 95/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9778\n",
            "Epoch 96/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0976 - val_acc: 0.9750\n",
            "Epoch 97/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0939 - val_acc: 0.9778\n",
            "Epoch 98/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0905 - val_acc: 0.9750\n",
            "Epoch 99/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0875 - val_acc: 0.9722\n",
            "Epoch 100/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9722\n",
            "Epoch 101/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9750\n",
            "Epoch 102/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9722\n",
            "Epoch 103/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9750\n",
            "Epoch 104/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0932 - val_acc: 0.9750\n",
            "Epoch 105/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0854 - val_acc: 0.9750\n",
            "Epoch 106/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9750\n",
            "Epoch 107/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0948 - val_acc: 0.9750\n",
            "Epoch 108/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0920 - val_acc: 0.9750\n",
            "Epoch 109/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9750\n",
            "Epoch 110/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0973 - val_acc: 0.9750\n",
            "Epoch 111/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9722\n",
            "Epoch 112/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0964 - val_acc: 0.9750\n",
            "Epoch 113/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0980 - val_acc: 0.9750\n",
            "Epoch 114/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1021 - val_acc: 0.9750\n",
            "Epoch 115/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9722\n",
            "Epoch 116/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0924 - val_acc: 0.9722\n",
            "Epoch 117/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0886 - val_acc: 0.9750\n",
            "Epoch 118/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1044 - val_acc: 0.9722\n",
            "Epoch 119/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0992 - val_acc: 0.9750\n",
            "Epoch 120/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0955 - val_acc: 0.9750\n"
          ]
        }
      ],
      "source": [
        "epocas = 120\n",
        "lote = 32\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=epocas, batch_size=lote, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtRc5CNUdNYY"
      },
      "source": [
        "### Plot history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "q0ADZz-vdTo-",
        "outputId": "7082b048-b4d9-4860-ecc3-231c546ac6b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title(\"History | val_acc: \"+str(history.history['val_acc'][len(history.history['val_acc'])-1]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0TBx3GleDIL"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPzS_SOseHSw"
      },
      "outputs": [],
      "source": [
        "model_name = \"mnist_model.h5\"\n",
        "model.save(\"models/\" + model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5rUnwGJxlS9"
      },
      "source": [
        "## Convert model for inference in the microcontroller using EmbedIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qPdjdamllew"
      },
      "source": [
        "### Configuration and execution of the exporter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-ZMFYFEt2hQ",
        "outputId": "533b7856-0e1f-474b-c50b-69e65a07c974"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"EmbedIA_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 3, 3, 8)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 2, 2, 16)          528       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,818\n",
            "Trainable params: 1,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "[[  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0  99   0   0   0   0   0   0]\n",
            " [  0   0   0  93   0   0   0   0   6   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0   0  99   0   0   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0   0  99   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  99   0]\n",
            " [  0   0   0   0   0  99   0   0   0   0]\n",
            " [  2   0   0   0   0   0  96   0   0   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0  99   0   0   0   0]\n",
            " [  0   0   0  99   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0 100   0   0   0   0]\n",
            " [  0   0 100   0   0   0   0   0   0   0]\n",
            " [  9   0  90   0   0   0   0   0   0   0]\n",
            " [  0  99   0   0   0   0   0   0   0   0]]\n",
            "\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "| Layer(activation) | Name          | #Param(NT) |   Shape    | MACs | Size (KiB) |\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "| Conv2D(relu)      | conv2d        |         80 | (6, 6, 8)  | 2592 |     0.219  |\n",
            "| MaxPooling2D      | max_pooling2d |          0 | (3, 3, 8)  |    0 |     0.000  |\n",
            "| Conv2D(relu)      | conv2d_1      |        528 | (2, 2, 16) | 2048 |     1.156  |\n",
            "| Flatten           | flatten       |          0 |   (64,)    |    0 |     0.000  |\n",
            "| Dense(relu)       | dense         |       1040 |   (16,)    | 1024 |     2.094  |\n",
            "| Dense(softmax)    | dense_1       |        170 |   (10,)    |  160 |     0.371  |\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "Total params (NT)....: 1818\n",
            "Total size in KiB....: 3.840\n",
            "Total MACs operations: 5824\n",
            "\n",
            "Project mnist_project exported in outputs/\n",
            "+EmbedIA_model stats--------------------------------------------------------+\n",
            "| Layer          Input prec.         Outputs  # 32-bit  Memory  32-bit MACs |\n",
            "|                      (bit)                       x 1    (kB)              |\n",
            "+---------------------------------------------------------------------------+\n",
            "| conv2d                   -   (-1, 6, 6, 8)        80    0.31         2592 |\n",
            "| max_pooling2d            -   (-1, 3, 3, 8)         0       0            0 |\n",
            "| conv2d_1                 -  (-1, 2, 2, 16)       528    2.06         2048 |\n",
            "| flatten                  -        (-1, 64)         0       0            0 |\n",
            "| dense                    -        (-1, 16)      1040    4.06         1024 |\n",
            "| dense_1                  -        (-1, 10)       170    0.66          160 |\n",
            "+---------------------------------------------------------------------------+\n",
            "| Total                                           1818    7.10         5824 |\n",
            "+---------------------------------------------------------------------------+\n",
            "+EmbedIA_model summary--------------------+\n",
            "| Total params                   1.82 k   |\n",
            "| Trainable params               1.82 k   |\n",
            "| Non-trainable params           0        |\n",
            "| Model size                     7.10 KiB |\n",
            "| Model size (8-bit FP weights)  1.78 KiB |\n",
            "| Float-32 Equivalent            7.10 KiB |\n",
            "| Compression Ratio of Memory    1.00     |\n",
            "| Number of MACs                 5.82 k   |\n",
            "+-----------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "# add parent folder to path in order to find EmbedIA folder\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "from embedia.project_generator import ProjectGenerator\n",
        "from embedia.model_generator.project_options import (\n",
        "    ModelDataType,\n",
        "    DebugMode,\n",
        "    ProjectFiles,\n",
        "    ProjectOptions,\n",
        "    ProjectType\n",
        ")\n",
        "\n",
        "\n",
        "OUTPUT_FOLDER = 'outputs/'\n",
        "PROJECT_NAME = 'mnist_project'\n",
        "\n",
        "MODEL_FILE = 'models/mnist_model.h5'\n",
        "\n",
        "model = load_model(MODEL_FILE)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "options = ProjectOptions()\n",
        "\n",
        "# set location of EmbedIA folder\n",
        "options.embedia_folder = '../EmbedIA/embedia'\n",
        "\n",
        "\n",
        "# options.project_type = ProjectType.ARDUINO\n",
        "# options.project_type = ProjectType.C\n",
        "options.project_type = ProjectType.CODEBLOCK\n",
        "# options.project_type = ProjectType.CPP\n",
        "\n",
        "# options.data_type = ModelDataType.FLOAT\n",
        "# options.data_type = ModelDataType.FIXED32\n",
        "options.data_type = ModelDataType.FIXED16\n",
        "# options.data_type = ModelDataType.FIXED8\n",
        "\n",
        "# options.debug_mode = DebugMode.DISCARD\n",
        "# options.debug_mode = DebugMode.DISABLED\n",
        "# options.debug_mode = DebugMode.HEADERS\n",
        "options.debug_mode = DebugMode.DATA\n",
        "\n",
        "samples = x_test[0:20]\n",
        "ids = y_test[0:20]\n",
        "\n",
        "res = model.predict(samples)\n",
        "print((res*100).astype('int'))\n",
        "\n",
        "options.example_data = samples\n",
        "options.example_ids = ids\n",
        "\n",
        "options.files = ProjectFiles.ALL\n",
        "# options.files = {ProjectFiles.MAIN}\n",
        "# options.files = {ProjectFiles.MODEL}\n",
        "# options.files = {ProjectFiles.LIBRARY}\n",
        "\n",
        "# if True, remove output folder and start a clean export\n",
        "options.clean_output = True\n",
        "\n",
        "############# Generate project #############\n",
        "\n",
        "generator = ProjectGenerator(options)\n",
        "generator.create_project(OUTPUT_FOLDER, PROJECT_NAME, model, options)\n",
        "\n",
        "print(\"Project\", PROJECT_NAME, \"exported in\", OUTPUT_FOLDER)\n",
        "\n",
        "import larq\n",
        "larq.models.summary(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLSr3oIoliLt"
      },
      "source": [
        "### Download generated project (Run only in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ULespOjpgrDP",
        "outputId": "e72de17e-3afe-4733-9117-04181ca2958b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/mnist_project/ (stored 0%)\n",
            "  adding: outputs/mnist_project/embedia_debug_def.h (deflated 69%)\n",
            "  adding: outputs/mnist_project/embedia_debug.c (deflated 76%)\n",
            "  adding: outputs/mnist_project/fixed.c (deflated 73%)\n",
            "  adding: outputs/mnist_project/example_file.h (deflated 95%)\n",
            "  adding: outputs/mnist_project/embedia.h (deflated 74%)\n",
            "  adding: outputs/mnist_project/fixed.h (deflated 74%)\n",
            "  adding: outputs/mnist_project/main.c (deflated 49%)\n",
            "  adding: outputs/mnist_project/mnist_project.cbp (deflated 74%)\n",
            "  adding: outputs/mnist_project/embedia.c (deflated 79%)\n",
            "  adding: outputs/mnist_project/embedia_model.h (deflated 59%)\n",
            "  adding: outputs/mnist_project/embedia_debug.h (deflated 55%)\n",
            "  adding: outputs/mnist_project/embedia_model.c (deflated 67%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bd00306-8e78-420b-8cd9-2f1b22f6faab\", \"embedia_project.zip\", 36846)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r embedia_project.zip 'outputs/mnist_project'\n",
        "files.download('/content/EmbedIA/embedia_project.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
