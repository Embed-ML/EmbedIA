{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt0VLZYvwmfD"
      },
      "source": [
        "<div align=\"left\">\n",
        "  <h1>EmbedIA</h1>\n",
        "  <p>EmbedIA is a machine learning framework for developing applications on microcontrollers.</p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9zpfPkcxbtd"
      },
      "source": [
        "## Import framework from Github (run only in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install larq"
      ],
      "metadata": {
        "id": "VHVRNEBYewqv",
        "outputId": "651b92cd-0ba4-41f0-eb67-19deecc243d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting larq\n",
            "  Downloading larq-0.13.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting terminaltables>=3.1.0\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging>=19.2 in /usr/local/lib/python3.9/dist-packages (from larq) (23.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from larq) (1.22.4)\n",
            "Installing collected packages: terminaltables, larq\n",
            "Successfully installed larq-0.13.0 terminaltables-3.1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LT3-lW8o_vt",
        "outputId": "1ed08bad-adbe-4889-d7bc-c1f9869d5f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EmbedIA'...\n",
            "remote: Enumerating objects: 815, done.\u001b[K\n",
            "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 815 (delta 26), reused 21 (delta 21), pack-reused 779\u001b[K\n",
            "Receiving objects: 100% (815/815), 12.22 MiB | 16.38 MiB/s, done.\n",
            "Resolving deltas: 100% (435/435), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Embed-ML/EmbedIA.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9uOnWBJtr0p",
        "outputId": "268a7c3e-04b9-43d1-f42b-52ac21afb812"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/EmbedIA\n"
          ]
        }
      ],
      "source": [
        "%cd EmbedIA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuRohaVQYgyR"
      },
      "source": [
        "## Load dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOZh360UZMYR",
        "outputId": "81d79a1f-48d0-45ef-b38d-7bffc3f1cdd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape (1437, 8, 8, 1)\n",
            "x_test.shape (360, 8, 8, 1)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 0 to not apply normalization\n",
        "# 1 for normalization [-0.5, 0.5], \n",
        "# 2 for normalization z score, \n",
        "_normalize = 2 \n",
        "\n",
        "def normalization0dot5(x):\n",
        "    '''\n",
        "        Normalization of values in the range [-0.5; 0.5]\n",
        "        Params:\n",
        "            x: numpy array to be normalized\n",
        "        Return:\n",
        "            x: normalized numpy array\n",
        "    '''\n",
        "    x = x/np.max(x)\n",
        "    x = x-0.5\n",
        "    return x\n",
        "\n",
        "def z_score(X_train, x_test):\n",
        "    '''\n",
        "        Normalization z score, uses mean and standard deviation of train vector\n",
        "        Params:\n",
        "            X_train: array of train numpy to be normalized\n",
        "            x_test: array of test numpy to be normalized\n",
        "        Return:\n",
        "            x_train, x_test: normalized numpy vectors\n",
        "    '''\n",
        "    x_mean= np.mean(X_train)\n",
        "    x_std= np.std(X_train)\n",
        "    \n",
        "    x_train= (X_train-x_mean)/x_std\n",
        "    x_test= (x_test-x_mean)/x_std\n",
        "    return x_train, x_test\n",
        "\n",
        "def load_dataset(_normalize):\n",
        "    '''\n",
        "        Load the sklearn digits dataset, applying the indicated normalization.\n",
        "        Params:\n",
        "            _normalize: normalization to be applied\n",
        "        Return:\n",
        "           X_train, X_test: training set\n",
        "           y_train, y_test: test set\n",
        "    '''\n",
        "\n",
        "    digits = load_digits()\n",
        "    \n",
        "    if _normalize == 1:\n",
        "        digits.images = normalization0dot5(digits.images)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(digits.images , digits.target, test_size=0.2, shuffle=True)\n",
        "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
        "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
        "\n",
        "    if _normalize == 2:\n",
        "        X_train, X_test = z_score(X_train, X_test)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "x_train, x_test, y_train, y_test = load_dataset(_normalize)\n",
        "\n",
        "print('x_train.shape', x_train.shape)\n",
        "print('x_test.shape', x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmUZiTEGcADx"
      },
      "source": [
        "## Creating and training a CNN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b7ZtwtOcXqq",
        "outputId": "c1c4ac69-ba95-47b5-8504-ead35ce33ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"EmbedIA_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 6, 6, 8)           80        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 3, 3, 8)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 2, 2, 16)          528       \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                1040      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,818\n",
            "Trainable params: 1,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, AveragePooling2D, BatchNormalization\n",
        "\n",
        "def create_model(x_train, y_train, y_test):\n",
        "    '''\n",
        "        Create a model\n",
        "        Input parameters:\n",
        "            x_train: training data\n",
        "            y_train, y_test: labels of the data involved (including test data)\n",
        "\n",
        "        return\n",
        "            model: sequential layers model\n",
        "    '''\n",
        "    classes = max(y_test.max(),y_train.max())+1\n",
        "\n",
        "    model = Sequential(name=\"EmbedIA_model\")\n",
        "\n",
        "    model.add(Conv2D(8, kernel_size=(3, 3), input_shape=x_train[0].shape,activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(16, kernel_size=(2, 2),activation='relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(16,activation='relu'))\n",
        "    model.add(Dense(classes,activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', \n",
        "                    loss='sparse_categorical_crossentropy', \n",
        "                    metrics=['acc'])\n",
        "    return model\n",
        "\n",
        "model = create_model(x_train, y_train, y_test)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dNA75Qmc0zx"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyyEsZKpco9z",
        "outputId": "d918ca72-359a-4f58-e142-a7756f973d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "45/45 [==============================] - 3s 18ms/step - loss: 2.1828 - acc: 0.2916 - val_loss: 1.9998 - val_acc: 0.3806\n",
            "Epoch 2/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.8156 - acc: 0.4537 - val_loss: 1.5741 - val_acc: 0.5694\n",
            "Epoch 3/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1.3183 - acc: 0.6799 - val_loss: 1.0747 - val_acc: 0.7444\n",
            "Epoch 4/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.8629 - acc: 0.8051 - val_loss: 0.6949 - val_acc: 0.8333\n",
            "Epoch 5/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.5842 - acc: 0.8539 - val_loss: 0.4997 - val_acc: 0.8917\n",
            "Epoch 6/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.4323 - acc: 0.8782 - val_loss: 0.3947 - val_acc: 0.9250\n",
            "Epoch 7/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.9061 - val_loss: 0.3121 - val_acc: 0.9361\n",
            "Epoch 8/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.2804 - acc: 0.9186 - val_loss: 0.3043 - val_acc: 0.9250\n",
            "Epoch 9/120\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.2451 - acc: 0.9304 - val_loss: 0.2393 - val_acc: 0.9472\n",
            "Epoch 10/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.2108 - acc: 0.9422 - val_loss: 0.2247 - val_acc: 0.9500\n",
            "Epoch 11/120\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.1850 - acc: 0.9582 - val_loss: 0.1946 - val_acc: 0.9639\n",
            "Epoch 12/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.1695 - acc: 0.9562 - val_loss: 0.1774 - val_acc: 0.9611\n",
            "Epoch 13/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.1522 - acc: 0.9631 - val_loss: 0.1652 - val_acc: 0.9639\n",
            "Epoch 14/120\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 0.1377 - acc: 0.9680 - val_loss: 0.1577 - val_acc: 0.9667\n",
            "Epoch 15/120\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 0.1261 - acc: 0.9722 - val_loss: 0.1698 - val_acc: 0.9583\n",
            "Epoch 16/120\n",
            "45/45 [==============================] - 1s 15ms/step - loss: 0.1160 - acc: 0.9715 - val_loss: 0.1448 - val_acc: 0.9694\n",
            "Epoch 17/120\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.1098 - acc: 0.9694 - val_loss: 0.1397 - val_acc: 0.9722\n",
            "Epoch 18/120\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 0.1043 - acc: 0.9743 - val_loss: 0.1269 - val_acc: 0.9722\n",
            "Epoch 19/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0956 - acc: 0.9736 - val_loss: 0.1317 - val_acc: 0.9639\n",
            "Epoch 20/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0877 - acc: 0.9798 - val_loss: 0.1328 - val_acc: 0.9694\n",
            "Epoch 21/120\n",
            "45/45 [==============================] - 0s 11ms/step - loss: 0.0876 - acc: 0.9763 - val_loss: 0.1202 - val_acc: 0.9694\n",
            "Epoch 22/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0779 - acc: 0.9798 - val_loss: 0.1564 - val_acc: 0.9583\n",
            "Epoch 23/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0759 - acc: 0.9833 - val_loss: 0.1250 - val_acc: 0.9722\n",
            "Epoch 24/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0684 - acc: 0.9819 - val_loss: 0.1160 - val_acc: 0.9722\n",
            "Epoch 25/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0652 - acc: 0.9826 - val_loss: 0.1429 - val_acc: 0.9556\n",
            "Epoch 26/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0640 - acc: 0.9847 - val_loss: 0.1144 - val_acc: 0.9722\n",
            "Epoch 27/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0623 - acc: 0.9833 - val_loss: 0.1190 - val_acc: 0.9694\n",
            "Epoch 28/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0555 - acc: 0.9861 - val_loss: 0.1039 - val_acc: 0.9750\n",
            "Epoch 29/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0540 - acc: 0.9861 - val_loss: 0.1179 - val_acc: 0.9722\n",
            "Epoch 30/120\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 0.0520 - acc: 0.9868 - val_loss: 0.1077 - val_acc: 0.9778\n",
            "Epoch 31/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0479 - acc: 0.9882 - val_loss: 0.1078 - val_acc: 0.9722\n",
            "Epoch 32/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0494 - acc: 0.9889 - val_loss: 0.1088 - val_acc: 0.9722\n",
            "Epoch 33/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0473 - acc: 0.9861 - val_loss: 0.1047 - val_acc: 0.9750\n",
            "Epoch 34/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0422 - acc: 0.9903 - val_loss: 0.1180 - val_acc: 0.9694\n",
            "Epoch 35/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0435 - acc: 0.9882 - val_loss: 0.0954 - val_acc: 0.9806\n",
            "Epoch 36/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0377 - acc: 0.9903 - val_loss: 0.1040 - val_acc: 0.9806\n",
            "Epoch 37/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0373 - acc: 0.9923 - val_loss: 0.1002 - val_acc: 0.9806\n",
            "Epoch 38/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0357 - acc: 0.9930 - val_loss: 0.0995 - val_acc: 0.9806\n",
            "Epoch 39/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0324 - acc: 0.9937 - val_loss: 0.1059 - val_acc: 0.9778\n",
            "Epoch 40/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0369 - acc: 0.9910 - val_loss: 0.0980 - val_acc: 0.9806\n",
            "Epoch 41/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0305 - acc: 0.9944 - val_loss: 0.1083 - val_acc: 0.9750\n",
            "Epoch 42/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0294 - acc: 0.9923 - val_loss: 0.1146 - val_acc: 0.9722\n",
            "Epoch 43/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0272 - acc: 0.9944 - val_loss: 0.1046 - val_acc: 0.9750\n",
            "Epoch 44/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0265 - acc: 0.9958 - val_loss: 0.1073 - val_acc: 0.9750\n",
            "Epoch 45/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0239 - acc: 0.9958 - val_loss: 0.1053 - val_acc: 0.9750\n",
            "Epoch 46/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0220 - acc: 0.9979 - val_loss: 0.1034 - val_acc: 0.9778\n",
            "Epoch 47/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0240 - acc: 0.9958 - val_loss: 0.1009 - val_acc: 0.9750\n",
            "Epoch 48/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0220 - acc: 0.9958 - val_loss: 0.1082 - val_acc: 0.9722\n",
            "Epoch 49/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0207 - acc: 0.9972 - val_loss: 0.1113 - val_acc: 0.9750\n",
            "Epoch 50/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0196 - acc: 0.9979 - val_loss: 0.0872 - val_acc: 0.9833\n",
            "Epoch 51/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0195 - acc: 0.9972 - val_loss: 0.0993 - val_acc: 0.9750\n",
            "Epoch 52/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0187 - acc: 0.9965 - val_loss: 0.0963 - val_acc: 0.9833\n",
            "Epoch 53/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0192 - acc: 0.9958 - val_loss: 0.0981 - val_acc: 0.9833\n",
            "Epoch 54/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0147 - acc: 0.9986 - val_loss: 0.1054 - val_acc: 0.9750\n",
            "Epoch 55/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0163 - acc: 0.9972 - val_loss: 0.0987 - val_acc: 0.9833\n",
            "Epoch 56/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0153 - acc: 0.9993 - val_loss: 0.0990 - val_acc: 0.9778\n",
            "Epoch 57/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0152 - acc: 0.9986 - val_loss: 0.1015 - val_acc: 0.9750\n",
            "Epoch 58/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 0.1262 - val_acc: 0.9722\n",
            "Epoch 59/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9806\n",
            "Epoch 60/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0126 - acc: 0.9986 - val_loss: 0.0993 - val_acc: 0.9833\n",
            "Epoch 61/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0123 - acc: 0.9993 - val_loss: 0.0990 - val_acc: 0.9750\n",
            "Epoch 62/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0110 - acc: 0.9993 - val_loss: 0.0952 - val_acc: 0.9861\n",
            "Epoch 63/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0114 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9806\n",
            "Epoch 64/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9833\n",
            "Epoch 65/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 0.0917 - val_acc: 0.9861\n",
            "Epoch 66/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0944 - val_acc: 0.9833\n",
            "Epoch 67/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.0994 - val_acc: 0.9806\n",
            "Epoch 68/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0085 - acc: 0.9993 - val_loss: 0.0885 - val_acc: 0.9861\n",
            "Epoch 69/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 0.1010 - val_acc: 0.9806\n",
            "Epoch 70/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 0.1083 - val_acc: 0.9806\n",
            "Epoch 71/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0082 - acc: 0.9993 - val_loss: 0.0962 - val_acc: 0.9861\n",
            "Epoch 72/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0933 - val_acc: 0.9861\n",
            "Epoch 73/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.0969 - val_acc: 0.9889\n",
            "Epoch 74/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0953 - val_acc: 0.9833\n",
            "Epoch 75/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0069 - acc: 0.9993 - val_loss: 0.0968 - val_acc: 0.9806\n",
            "Epoch 76/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1013 - val_acc: 0.9806\n",
            "Epoch 77/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0957 - val_acc: 0.9833\n",
            "Epoch 78/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9833\n",
            "Epoch 79/120\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.1019 - val_acc: 0.9750\n",
            "Epoch 80/120\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 0.1020 - val_acc: 0.9806\n",
            "Epoch 81/120\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 0.1119 - val_acc: 0.9778\n",
            "Epoch 82/120\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0991 - val_acc: 0.9806\n",
            "Epoch 83/120\n",
            "45/45 [==============================] - 0s 10ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 0.1016 - val_acc: 0.9833\n",
            "Epoch 84/120\n",
            "45/45 [==============================] - 1s 15ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9778\n",
            "Epoch 85/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 0.1199 - val_acc: 0.9750\n",
            "Epoch 86/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1069 - val_acc: 0.9806\n",
            "Epoch 87/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.1089 - val_acc: 0.9833\n",
            "Epoch 88/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 0.1064 - val_acc: 0.9833\n",
            "Epoch 89/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0998 - val_acc: 0.9861\n",
            "Epoch 90/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9833\n",
            "Epoch 91/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1028 - val_acc: 0.9833\n",
            "Epoch 92/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 0.1050 - val_acc: 0.9833\n",
            "Epoch 93/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1143 - val_acc: 0.9750\n",
            "Epoch 94/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9806\n",
            "Epoch 95/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9833\n",
            "Epoch 96/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1115 - val_acc: 0.9806\n",
            "Epoch 97/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1108 - val_acc: 0.9806\n",
            "Epoch 98/120\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.1072 - val_acc: 0.9778\n",
            "Epoch 99/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1079 - val_acc: 0.9861\n",
            "Epoch 100/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1059 - val_acc: 0.9833\n",
            "Epoch 101/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9806\n",
            "Epoch 102/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1062 - val_acc: 0.9889\n",
            "Epoch 103/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.1060 - val_acc: 0.9889\n",
            "Epoch 104/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9889\n",
            "Epoch 105/120\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9861\n",
            "Epoch 106/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.1040 - val_acc: 0.9861\n",
            "Epoch 107/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1102 - val_acc: 0.9861\n",
            "Epoch 108/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9861\n",
            "Epoch 109/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.1101 - val_acc: 0.9806\n",
            "Epoch 110/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9806\n",
            "Epoch 111/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9889\n",
            "Epoch 112/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9833\n",
            "Epoch 113/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.1128 - val_acc: 0.9833\n",
            "Epoch 114/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1087 - val_acc: 0.9861\n",
            "Epoch 115/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.1080 - val_acc: 0.9861\n",
            "Epoch 116/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1098 - val_acc: 0.9861\n",
            "Epoch 117/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1154 - val_acc: 0.9806\n",
            "Epoch 118/120\n",
            "45/45 [==============================] - 0s 4ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.1094 - val_acc: 0.9861\n",
            "Epoch 119/120\n",
            "45/45 [==============================] - 0s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.1120 - val_acc: 0.9833\n",
            "Epoch 120/120\n",
            "45/45 [==============================] - 0s 5ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.1118 - val_acc: 0.9889\n"
          ]
        }
      ],
      "source": [
        "epocas = 120\n",
        "lote = 32\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=epocas, batch_size=lote, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtRc5CNUdNYY"
      },
      "source": [
        "### Plot history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "q0ADZz-vdTo-",
        "outputId": "b9daafeb-e5e0-4f13-c708-0620c54ce082"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title(\"History | val_acc: \"+str(history.history['val_acc'][len(history.history['val_acc'])-1]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0TBx3GleDIL"
      },
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uPzS_SOseHSw"
      },
      "outputs": [],
      "source": [
        "model_name = \"mnist_model.h5\"\n",
        "model.save(\"models/\" + model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5rUnwGJxlS9"
      },
      "source": [
        "## Convert model for inference in the microcontroller using EmbedIA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configuration and execution of the exporter { display-mode: \"form\" }\n",
        "\n",
        "import sys\n",
        "# add parent folder to path in order to find EmbedIA folder\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "from embedia.project_generator import ProjectGenerator\n",
        "from embedia.model_generator.project_options import (\n",
        "    ModelDataType,\n",
        "    DebugMode,\n",
        "    ProjectFiles,\n",
        "    ProjectOptions,\n",
        "    ProjectType\n",
        ")\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ###Export adjustment\n",
        "\n",
        "OUTPUT_FOLDER = 'outputs/' #@param {type:\"string\"}\n",
        "PROJECT_NAME = 'mnist_project' #@param {type:\"string\"}\n",
        "\n",
        "MODEL_FILE = 'models/mnist_model.h5' #@param {type:\"string\"}\n",
        "model = load_model(MODEL_FILE)\n",
        "# model.summary()\n",
        "\n",
        "options = ProjectOptions()\n",
        "\n",
        "# set location of EmbedIA folder\n",
        "embedia_folder = '../EmbedIA/embedia'\n",
        "options.embedia_folder = embedia_folder\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ###Configuration of the project to export\n",
        "\n",
        "# set project type\n",
        "project_type_dict = {\n",
        "    \"ARDUINO\": ProjectType.ARDUINO, \n",
        "    \"C\": ProjectType.C,\n",
        "    \"CODEBLOCK\": ProjectType.CODEBLOCK,\n",
        "    \"CPP\": ProjectType.CPP,\n",
        "}\n",
        "project_type = \"CODEBLOCK\" #@param [\"ARDUINO\", \"C\", \"CODEBLOCK\", \"CPP\"]\n",
        "options.project_type = project_type_dict[project_type]\n",
        "\n",
        "# set data type\n",
        "data_type_dict = {\n",
        "    \"FLOAT\": ModelDataType.FLOAT, \n",
        "    \"FIXED32\": ModelDataType.FIXED32,\n",
        "    \"FIXED16\": ModelDataType.FIXED16,\n",
        "    \"FIXED8\": ModelDataType.FIXED8,\n",
        "    \"BINARY\": ModelDataType.BINARY,\n",
        "}\n",
        "data_type = \"FIXED16\" #@param [\"FLOAT\", \"FIXED32\", \"FIXED16\", \"FIXED8\", \"BINARY\"]\n",
        "options.data_type = data_type_dict[data_type]\n",
        "\n",
        "# set debug mode\n",
        "debug_mode_dict = {\n",
        "    \"DISCARD\": DebugMode.DISCARD, \n",
        "    \"DISABLED\": DebugMode.DISABLED,\n",
        "    \"HEADERS\": DebugMode.HEADERS,\n",
        "    \"DATA\": DebugMode.DATA,\n",
        "}\n",
        "debug_mode = \"DATA\" #@param [\"DISCARD\", \"DISABLED\", \"HEADERS\", \"DATA\"]\n",
        "options.debug_mode = debug_mode_dict[debug_mode]\n",
        "\n",
        "# set which files to export\n",
        "files_export_dict = {\n",
        "    \"ALL\": ProjectFiles.ALL, \n",
        "    \"MAIN\": {ProjectFiles.MAIN},\n",
        "    \"MODEL\": {ProjectFiles.MODEL},\n",
        "    \"LIBRARY\": {ProjectFiles.LIBRARY},\n",
        "}\n",
        "files_export = \"ALL\" #@param [\"ALL\", \"MAIN\", \"MODEL\", \"LIBRARY\"]\n",
        "options.files = files_export_dict[files_export]\n",
        "\n",
        "# examples to export\n",
        "samples = x_test[0:10]\n",
        "ids = y_test[0:10]\n",
        "\n",
        "res = model.predict(samples)\n",
        "print((res*100).astype('int'))\n",
        "\n",
        "options.example_data = samples\n",
        "options.example_ids = ids\n",
        "\n",
        "#@markdown if True, remove output folder and start a clean export:\n",
        "clean_output = True #@param {type:\"boolean\"}\n",
        "options.clean_output = clean_output\n",
        "#@markdown ---\n",
        "\n",
        "############# Generate project #############\n",
        "\n",
        "generator = ProjectGenerator(options)\n",
        "generator.create_project(OUTPUT_FOLDER, PROJECT_NAME, model, options)\n",
        "\n",
        "print(\"Project\", PROJECT_NAME, \"exported in\", OUTPUT_FOLDER,'\\n\\n')\n",
        "\n",
        "import larq\n",
        "larq.models.summary(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhG3zKBxHFOg",
        "outputId": "e3d72e18-9031-40fe-dab5-eba2e0410082"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fab8ccea430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step\n",
            "[[  0   0  99   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0  99   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0   0   0  99]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0  99   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  99   0   0]\n",
            " [  0   0   0   0 100   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 100   0   0   0]]\n",
            "\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "| Layer(activation) | Name          | #Param(NT) |   Shape    | MACs | Size (KiB) |\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "| Conv2D(relu)      | conv2d        |         80 | (6, 6, 8)  | 2592 |     0.219  |\n",
            "| MaxPooling2D      | max_pooling2d |          0 | (3, 3, 8)  |    0 |     0.000  |\n",
            "| Conv2D(relu)      | conv2d_1      |        528 | (2, 2, 16) | 2048 |     1.156  |\n",
            "| Flatten           | flatten       |          0 |   (64,)    |    0 |     0.000  |\n",
            "| Dense(relu)       | dense         |       1040 |   (16,)    | 1024 |     2.094  |\n",
            "| Dense(softmax)    | dense_1       |        170 |   (10,)    |  160 |     0.371  |\n",
            "+-------------------+---------------+------------+------------+------+------------+\n",
            "Total params (NT)....: 1818\n",
            "Total size in KiB....: 3.840\n",
            "Total MACs operations: 5824\n",
            "\n",
            "Project mnist_project exported in outputs/ \n",
            "\n",
            "\n",
            "+EmbedIA_model stats--------------------------------------------------------+\n",
            "| Layer          Input prec.         Outputs  # 32-bit  Memory  32-bit MACs |\n",
            "|                      (bit)                       x 1    (kB)              |\n",
            "+---------------------------------------------------------------------------+\n",
            "| conv2d                   -   (-1, 6, 6, 8)        80    0.31         2592 |\n",
            "| max_pooling2d            -   (-1, 3, 3, 8)         0       0            0 |\n",
            "| conv2d_1                 -  (-1, 2, 2, 16)       528    2.06         2048 |\n",
            "| flatten                  -        (-1, 64)         0       0            0 |\n",
            "| dense                    -        (-1, 16)      1040    4.06         1024 |\n",
            "| dense_1                  -        (-1, 10)       170    0.66          160 |\n",
            "+---------------------------------------------------------------------------+\n",
            "| Total                                           1818    7.10         5824 |\n",
            "+---------------------------------------------------------------------------+\n",
            "+EmbedIA_model summary--------------------+\n",
            "| Total params                   1.82 k   |\n",
            "| Trainable params               1.82 k   |\n",
            "| Non-trainable params           0        |\n",
            "| Model size                     7.10 KiB |\n",
            "| Model size (8-bit FP weights)  1.78 KiB |\n",
            "| Float-32 Equivalent            7.10 KiB |\n",
            "| Compression Ratio of Memory    1.00     |\n",
            "| Number of MACs                 5.82 k   |\n",
            "+-----------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLSr3oIoliLt"
      },
      "source": [
        "### Download generated project (Run only in Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "ULespOjpgrDP",
        "outputId": "83502c14-4984-4899-e40f-bd3851a3c23a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: outputs/mnist_project/ (stored 0%)\n",
            "updating: outputs/mnist_project/embedia_debug_def.h (deflated 69%)\n",
            "updating: outputs/mnist_project/embedia_debug.c (deflated 76%)\n",
            "updating: outputs/mnist_project/fixed.c (deflated 73%)\n",
            "updating: outputs/mnist_project/example_file.h (deflated 94%)\n",
            "updating: outputs/mnist_project/embedia.h (deflated 74%)\n",
            "updating: outputs/mnist_project/fixed.h (deflated 74%)\n",
            "updating: outputs/mnist_project/main.c (deflated 49%)\n",
            "updating: outputs/mnist_project/mnist_project.cbp (deflated 74%)\n",
            "updating: outputs/mnist_project/embedia.c (deflated 79%)\n",
            "updating: outputs/mnist_project/embedia_model.h (deflated 59%)\n",
            "updating: outputs/mnist_project/embedia_debug.h (deflated 55%)\n",
            "updating: outputs/mnist_project/embedia_model.c (deflated 67%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6b113613-2e5e-455a-90b5-92840a62e639\", \"embedia_project.zip\", 35984)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "!zip -r embedia_project.zip 'outputs/mnist_project'\n",
        "files.download('/content/EmbedIA/embedia_project.zip')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
